# -*- coding: utf-8 -*-
"""Copy of Extract SECOP II.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1o9WgEj8redwspRR2KJg3ri8ZqMfk-qPD

https://www.colombiacompra.gov.co/transparencia/datos-abiertos/conjuntos-de-datos-abiertos

**0. Cargar la base  de Gesti√≥n administrativa**
"""

## 0. CARGAR BASE DE GESTI√ìN ADMINISTRATIVA

import pandas as pd
import os, io

df=pd.read_excel(r"C:\Users\Natalia\Downloads\Atenea\GestionAdministrativa.xlsx")

# 4) Verificar
print("Dimensiones:", df.shape)
df.head()

"""**Diccionario Areas**"""

import pandas as pd  # <-- faltaba

## vamor a usar este diccionario despu√©s con la base de datos del PAA
Diccionario_Dependencia = pd.DataFrame(
    [
        ("DIRECCI√ìN GENERAL", "DES"),
        ("GERENCIA DE CIENCIA, TECNOLOG√çA E INNOVACI√ìN", "GCTI"),
        ("GERENCIA DE EDUCACI√ìN POSMEDIA", "GEP"),
        ("GERENCIA DE ESTRATEGIA", "GE"),
        ("OFICINA JUR√çDICA", "OJ"),
        ("SUB. GESTI√ìN_ADMINISTRATIVA", "SGA"),
        ("SUBGERENCIA DE AN√ÅLISIS DE INFORMACI√ìN Y GESTI√ìN DEL CONOCIMIENTO", "SAIGC"),
        ("SUBGERENCIA DE PLANEACI√ìN", "SPL"),
        ("SUBGERENCIA DE TECNOLOG√çAS DE LA INFORMACI√ìN Y LAS COMUNICACIONES", "TIC"),
        ("SUBGERENCIA FINANCIERA", "SGF"),
        ("OFICINA CONTROL INTERNO DISCIPLINARIO", "CID"),
        ("COMUNICACIONES","COM"),
        ("GERENCIA DE GESTI√ìN CORPORATIVA", "GGC"),
        ("OFICINA CONTROL INTERNO DISCIPLINARIO","OCID"),
        ("OFICINA DE CONTROL INTERNO DE GESTI√ìN", "OCIG"),
        ("TESORERIA", "TES"),

    ],
    columns=["DEPENDENCIA", "CODIGO_ID"]
)

# (Opcional) guardar a Excel
# Diccionario_Dependencia.to_excel("Diccionario_Dependencia.xlsx", index=False, engine="openpyxl")

Diccionario_Dependencia.head()



"""**1. Extract SECOP II - Contratos electr√≥nicos**"""

# =============================================================================
# SECOP II (Socrata) -> Filtrar ATENEA 2025 (nombre + NIT exactos) -> Exportar a Excel
# Uso: Ejecutar en Google Colab.
# Qu√© hace:
#   1) Instala dependencias (requests, pandas, openpyxl) necesarias en Colab.
#   2) Construye una consulta SoQL para el dataset de Contratos Electr√≥nicos (jbjy-vk9h).
#   3) Filtra por:
#       - A√±o 2025 (fecha_de_firma entre 2025-01-01 y 2025-12-31).
#       - nombre_entidad EXACTO = "AGENCIA DISTRITAL PARA LA EDUCACI√ìN SUPERIOR, LA CIENCIA Y LA TECNOLOG√çA, ATENEA".
#       - nit_entidad EXACTO = "901508361".
#   4) Paginaci√≥n con $limit/$offset para traer todos los registros.
#   5) Exporta a un archivo Excel .xlsx en /content/ (descargable desde el panel de archivos de Colab).
# =============================================================================

# ---- PASO 0. Instalar dependencias en Colab ----
# - requests: para llamar la API REST de Socrata (SODA).
# - pandas: para estructurar los datos en DataFrame.
# - openpyxl: motor para escribir archivos .xlsx.
# !pip install -q requests pandas openpyxl

# ---- PASO 1. Importar librer√≠as ----
import requests   # llamadas HTTP
import pandas as pd  # manejo de DataFrame y exportar a Excel
import time       # pausas cortas por cortes√≠a con el API
import os         # (opcional) para leer variable SOCRATA_APP_TOKEN

# ---- PASO 2. Configuraci√≥n general ----
# Endpoint del dataset "SECOP II ‚Äì Contratos Electr√≥nicos" en datos.gov.co (Socrata/SODA).
BASE_URL = "https://www.datos.gov.co/resource/jbjy-vk9h.json"



# Tama√±o de p√°gina para la paginaci√≥n. En Socrata es t√≠pico usar hasta 50.000.
CHUNK_SIZE = 50000

# Ruta/Nombre del archivo de salida en el entorno de Colab (panel de archivos a la izquierda).
OUTPUT_XLSX = "/content/SECOPII_ATENEA.xlsx"

# (Opcional) App Token mejora l√≠mites de tasa. Si lo tienes:
APP_TOKEN = os.getenv("SOCRATA_APP_TOKEN")  # o pon aqu√≠ el string del token

# ---- PASO 3. Definir filtros EXACTOS de entidad ----
# Requisitos solicitados: nombre_entidad y nit_entidad deben coincidir EXACTAMENTE.
NOMBRE_EXACTO = "AGENCIA DISTRITAL PARA LA EDUCACI√ìN SUPERIOR, LA CIENCIA Y LA TECNOLOG√çA, ATENEA"
NIT_EXACTO = "901508361"

# ---- PASO 4. Definir ventana de fechas para 2025 ----

# Requiere: NADA m√°s que esta celda (no vuelve a cargar bases)
from datetime import datetime  # <- faltaba este import

# Filtramos por fecha_de_firma entre el 1 de enero y el 31 de diciembre de 2025.
year_start = "2025-01-01T00:00:00"

# "hoy" din√°mico (fecha y hora local). Si prefieres UTC, usa datetime.utcnow()
year_end = datetime.now().strftime("%Y-%m-%dT%H:%M:%S")

print("Rango de fecha_de_firma ->", year_start, "a", year_end)

# ---- PASO 5. Construir la cl√°usula SoQL ($where) ----
# - Usamos igualdad exacta en nombre_entidad y nit_entidad.
# - Importante: si el nombre contiene comillas simples, se deben escapar (doblar a '').
#   Para evitar el error "f-string expression part cannot include a backslash", calculamos
#   primero la variable `nombre_safe` y luego la insertamos en el f-string sin backslashes.
# ---- PASO 5. Construir la cl√°usula SoQL ($where) -----------------
# Usamos igualdad exacta en nombre_entidad y nit_entidad (si lo proporcionas).
# Esta celda no recalculta IDs ni lee archivos de nuevo.

import os

def soql_escape(value: str) -> str:
    """Escapa comillas simples para SoQL (dobla ' a '')."""
    if value is None:
        return ""
    return str(value).replace("'", "''").strip()

# >>> Ajusta estas variables si las traes de otra celda/variable en memoria:
NOMBRE_EXACTO = "AGENCIA DISTRITAL PARA LA EDUCACI√ìN SUPERIOR, LA CIENCIA Y LA TECNOLOG√çA, ATENEA"
NIT_EXACTO = "901508361"   # Si lo tienes como n√∫mero, str() est√° bien

nombre_safe = soql_escape(NOMBRE_EXACTO)

# ‚ö† nit_entidad en datos.gov.co suele venir como texto; por compatibilidad lo comparamos como texto.
# Si tu recurso lo tiene num√©rico, elimina las comillas alrededor de {nit_safe}.
nit_safe = soql_escape(NIT_EXACTO)

where_clause = (
    f"fecha_de_firma between '{year_start}' and '{year_end}' "
    f"AND nombre_entidad = '{nombre_safe}' "
    f"AND nit_entidad = '{nit_safe}'"
)

print("Filtro SoQL:\n", where_clause)

# (Opcional) Si tienes un App Token de Socrata, a√±ade el header:
APP_TOKEN = os.getenv("SODA_APP_TOKEN") or os.getenv("APP_TOKEN")
headers = {"X-App-Token": APP_TOKEN} if APP_TOKEN else {}

# ---- PASO 6. Funci√≥n para descargar una "p√°gina" de resultados ----
# Usa $limit y $offset para traer lotes de tama√±o CHUNK_SIZE.
# $order por fecha_de_firma da un orden estable que evita solapamientos entre p√°ginas.
def fetch_page(offset, limit=CHUNK_SIZE):
    params = {
        "$where": where_clause,         # filtro SoQL (fechas + entidad + NIT)
        "$limit": limit,                # tama√±o de la p√°gina
        "$offset": offset,              # desplazamiento para paginaci√≥n
        "$order": "fecha_de_firma ASC"  # orden para consistencia entre p√°ginas
    }
    # Llamada a la API; timeout de 60s por si hay lotes grandes o red lenta.
    r = requests.get(BASE_URL, params=params, headers=headers, timeout=60)
    # Si la respuesta no es 2xx, lanzar√° excepci√≥n (√∫til para depurar).
    r.raise_for_status()
    # La API devuelve JSON; lo convertimos a objetos Python (lista de dicts).
    return r.json()

# ---- PASO 7. Bucle de paginaci√≥n para descargar TODO ----
# L√≥gica:
#   - Iniciar offset = 0.
#   - Llamar fetch_page(offset); si no retorna filas, hemos terminado.
#   - Acumular filas y aumentar offset en CHUNK_SIZE.
#   - Peque√±a pausa (time.sleep) para ser "buen ciudadano" con el API.
all_rows = []
offset = 0

print("Descargando contratos‚Ä¶")
while True:
    batch = fetch_page(offset)
    if not batch:          # si la "p√°gina" viene vac√≠a, ya no hay m√°s datos
        break
    all_rows.extend(batch) # agregar las filas de esta p√°gina al acumulado
    offset += CHUNK_SIZE   # avanzar el offset para la pr√≥xima p√°gina
    print(f"+ {len(batch)} registros (acumulado: {len(all_rows)})")
    time.sleep(0.25)       # üí° cortes√≠a con el API para evitar l√≠mites de tasa

print(f"\nTotal descargado: {len(all_rows)} registros")
df = pd.DataFrame(all_rows)
df.shape
df.info()

# ---- PASO 8. Convertir a DataFrame y exportar a Excel ----

if all_rows:
    df = pd.DataFrame(all_rows)

    # (Opcional) Renombrar columnas agregando sufijo (Contratos_electronicos) excepto 'id_contrato'
    rename_map = {
        c: f"{c} (Contratos_electronicos)"
        for c in df.columns
        if c != "id_contrato" and "(Contratos_electronicos)" not in c
    }
    df = df.rename(columns=rename_map)

    # (Opcional) Reordenar columnas si existen
    preferred_cols = [
        "nombre_entidad", "nit_entidad",
        "referencia_contrato", "objeto_contrato", "objeto_contractual",
        "proveedor_adjudicado", "documento_proveedor",
        "valor_del_contrato", "valor_total_adiciones",
        "fecha_de_firma", "fecha_inicio_ejecucion", "fecha_fin_ejecucion",
        "ciudad", "departamento", "sector", "link_secop_ii"
    ]
    ordered_cols = [c for c in preferred_cols if c in df.columns] + [c for c in df.columns if c not in preferred_cols]
    df = df[ordered_cols]

    # Tipos amigables
    for c in ["fecha_de_firma", "fecha_inicio_ejecucion", "fecha_fin_ejecucion"]:
        if c in df.columns:
            df[c] = pd.to_datetime(df[c], errors="coerce")

    for c in ["valor_del_contrato", "valor_total_adiciones"]:
        if c in df.columns:
            df[c] = pd.to_numeric(df[c], errors="coerce")


SECOPII_ATENEA = df

print(SECOPII_ATENEA.shape)
SECOPII_ATENEA.head()
SECOPII_ATENEA.info()


"""**2. Extract SECOP II -  Modificaciones a contratos**"""

# ================================
# 2) Extract SECOP II - Modificaciones a contratos
# Dataset Socrata: u8cx-r425 (Modificaciones a contratos SECOP II)
# ================================

import os, math, json, time, random, re
import pandas as pd
import requests
from requests.adapters import HTTPAdapter
from urllib3.util.retry import Retry

# --- Configuraci√≥n general ---
BASE_URL = "https://www.datos.gov.co/resource/u8cx-r425.json"   # Modificaciones
CHUNK_SIZE = 50000                                              # paginaci√≥n API
BATCH_IDS  = 150                                                # ids por lote en el WHERE IN
OUTPUT_XLSX_MODS   = "SECOPII_Modificaciones.xlsx"
OUTPUT_XLSX_MERGED = "SECOPII_ContratosElectronicos_Modificaciones.xlsx"

# (Opcional) token de Socrata para mejores l√≠mites
APP_TOKEN = os.getenv("SOCRATA_APP_TOKEN") or None  # o pon aqu√≠ tu token como string

def make_session():
    s = requests.Session()
    s.headers.update({"User-Agent": "Colab/SECOPII-Mods"})
    if APP_TOKEN:
        s.headers.update({"X-App-Token": APP_TOKEN})
    retry = Retry(total=4, backoff_factor=0.7, status_forcelist=[429,500,502,503,504])
    s.mount("https://", HTTPAdapter(max_retries=retry))
    return s

SESSION = make_session()

# -----------------------------
# 2.1 Obtener id_contrato √∫nicos desde SECOPII_ATENEA
# -----------------------------
def ensure_atenea_df():
    # Usa el DF en memoria si existe; de lo contrario intenta leer un XLSX local
    if "SECOPII_ATENEA" in globals():
        df_at = globals()["SECOPII_ATENEA"].copy()
    elif "df_atenea" in globals():  # por si tu DF se llama as√≠
        df_at = globals()["df_atenea"].copy()
    else:
        # Ajusta el nombre si tu archivo se llama distinto:
        fname_guess = "SECOPII_ATENEA.xlsx"
        if not os.path.exists(fname_guess):
            raise FileNotFoundError(
                f"No encuentro un DF 'SECOPII_ATENEA' en memoria ni el archivo '{fname_guess}'. "
                "C√°rgalo o cambia el nombre del archivo aqu√≠."
            )
        df_at = pd.read_excel(fname_guess)
    # Normaliza el tipo y nombre de columna
    assert "id_contrato" in df_at.columns, "La base SECOPII_ATENEA no tiene columna 'id_contrato'."
    df_at["id_contrato"] = df_at["id_contrato"].astype(str).str.strip()
    return df_at

SECOPII_ATENEA = ensure_atenea_df()
ids = pd.Series(SECOPII_ATENEA["id_contrato"].dropna().astype(str).str.strip().unique()).tolist()
print(f"üîé id_contrato √∫nicos en SECOPII_ATENEA: {len(ids):,}")

# -----------------------------
# 2.2 Descargar Modificaciones (u8cx-r425) solo para esos id_contrato
# -----------------------------


# -----------------------------

import os, math, time, random, requests
import pandas as pd
from typing import Optional

# ============ Utilidades SoQL ============
def soql_quote(value: str) -> str:
    """Devuelve el valor entre comillas simples escapando comillas internas para SoQL."""
    if value is None:
        return "''"
    return "'" + str(value).replace("'", "''").strip() + "'"

def quote_sql_list(values) -> str:
    """Convierte una lista en 'v1','v2','v3' para usar en IN (...)."""
    return ",".join(soql_quote(v) for v in values if v is not None)

# ============ Config de API ============
BASE_URL   = "https://www.datos.gov.co/resource/u8cx-r425.json"  # Modificaiones SECOP II
ID_FIELD   = "id_contrato"    # campo a filtrar en el recurso cb9c-h8sn
PAGE_SIZE  = 50000            # m√°ximo permitido por Socrata en $limit
ID_BATCH   = 80               # cu√°ntos ids por cl√°usula IN (...) para no alargar la URL
PAUSE_S    = 0.25             # cortes√≠a con la API entre llamadas
MAX_RETRY  = 4

# Headers con App Token (opcional pero recomendado)
headers = {}
_app_token = os.getenv("SODA_APP_TOKEN") or os.getenv("APP_TOKEN")
if _app_token:
    headers["X-App-Token"] = _app_token

# ============ Funci√≥n principal ============
def fetch_adiciones_for_ids(id_list,
                            id_field: str = ID_FIELD,
                            base_url: str = BASE_URL,
                            page_size: int = PAGE_SIZE,
                            id_batch_size: int = ID_BATCH,
                            session: Optional[requests.Session] = None) -> pd.DataFrame:
    """
    Descarga ADICIONES (cb9c-h8sn) filtrando por lotes de IDs con WHERE:
        id_field IN ('id1','id2',...)
    Hace paginaci√≥n $limit/$offset por cada lote.
    Devuelve un DataFrame con todo lo descargado (sin duplicados).
    """
    if session is None:
        session = requests.Session()

    # Normalizamos ids que llegaron desde la Secci√≥n 2 (no recalculamos √∫nicos ni nada)
    id_list = [str(x).strip() for x in list(id_list) if pd.notna(x)]
    if not id_list:
        print("‚ö†Ô∏è La lista de ids est√° vac√≠a. Nada que consultar.")
        return pd.DataFrame(columns=[id_field])

    total_ids     = len(id_list)
    total_batches = math.ceil(total_ids / id_batch_size)
    print(f"üîé Consultando MODIFICACIONES para {total_ids} contratos en {total_batches} lote(s)...")

    all_records = []
    for b in range(total_batches):
        batch = id_list[b*id_batch_size : (b+1)*id_batch_size]
        if not batch:
            continue

        # WHERE por lote (sin 'estado_modificacion' porque no existe en cb9c-h8sn)
        where = f"{id_field} IN ({quote_sql_list(batch)})"

        # Paginaci√≥n por $limit/$offset
        offset = 0
        while True:
            params = {
                "$select": "*",
                "$where":  where,
                "$order":  f"{id_field} ASC",
                "$limit":  page_size,
                "$offset": offset
            }

            # Reintentos ligeros para 429/5xx
            attempt = 0
            while True:
                attempt += 1
                r = session.get(base_url, params=params, headers=headers, timeout=60)
                if r.status_code == 200:
                    rows = r.json()
                    if isinstance(rows, dict):
                        rows = [rows]
                    break
                if r.status_code in (429, 500, 502, 503, 504) and attempt < MAX_RETRY:
                    wait_s = 1.5 ** attempt
                    print(f"‚è≥ {r.status_code} (lote {b+1}/{total_batches}, offset={offset}); reintento {attempt}/{MAX_RETRY} en {wait_s:.1f}s")
                    time.sleep(wait_s)
                    continue
                # Error no recuperable
                raise requests.HTTPError(f"HTTP {r.status_code} - {r.text[:250]}\nURL: {r.url}")

            if not rows:
                # P√°gina vac√≠a ‚Üí terminamos este lote
                break

            all_records.extend(rows)
            offset += page_size
            # Progreso visual
            print(f"   Lote {b+1}/{total_batches} +{len(rows)} (acum: {len(all_records)})")
            time.sleep(PAUSE_S)  # cortes√≠a con la API

        # Pausa breve entre lotes
        time.sleep(random.uniform(0.2, 0.6))

    # A DataFrame
    if not all_records:
        print("‚ö†Ô∏è No se recuperaron adiciones para los IDs suministrados.")
        return pd.DataFrame(columns=[id_field])

    df = pd.DataFrame(all_records)

    # Tipificaci√≥n ligera y deduplicaci√≥n
    if id_field in df.columns:
        df[id_field] = df[id_field].astype(str).str.strip()
    df = df.drop_duplicates()

    return df

# ============ Ejecuci√≥n de la descarga ============
# Usa los 'ids' que ya existen en memoria desde la Secci√≥n 2
if "ids" not in globals():
    raise RuntimeError("No encuentro la variable 'ids' en memoria. Ejecuta primero la Secci√≥n 2.")

SECOPII_Modificaciones = fetch_adiciones_for_ids(ids)

print(f"üìà Registros de Modificaciones descargados: {len(SECOPII_Modificaciones):,}")
SECOPII_Modificaciones.info()

# (Opcional) Guardar a Excel
OUTPUT_XLSX_MODS = "SECOPII_modificaciones.xlsx"
SECOPII_Modificaciones.to_excel(OUTPUT_XLSX_MODS, index=False)
print(f"üíæ Archivo generado: {OUTPUT_XLSX_MODS}")

## MERGE SOLAMENTE CON LA BASE DE MODIFICACIONES

# ================================
# 2.3 Merge: Modificaciones (LEFT) √ó ATENEA (RIGHT)
# ================================

# # Validaciones b√°sicas
# assert "SECOPII_Modificaciones" in globals(), "No encuentro SECOPII_Modificaciones en memoria."
# assert "SECOPII_ATENEA" in globals(), "No encuentro SECOPII_ATENEA en memoria."
# assert "id_contrato" in SECOPII_Modificaciones.columns, "SECOPII_Modificaciones no tiene 'id_contrato'."
# assert "id_contrato" in SECOPII_ATENEA.columns, "SECOPII_ATENEA no tiene 'id_contrato'."

# # Normaliza la llave en ambos DFs
# SECOPII_Modificaciones["id_contrato"] = SECOPII_Modificaciones["id_contrato"].astype(str).str.strip()
# SECOPII_ATENEA["id_contrato"]       = SECOPII_ATENEA["id_contrato"].astype(str).str.strip()

# # Renombrar TODAS las columnas que vienen de ATENEA (excepto la llave) con " (contratos_electronicos)"
# atenea_cols = [c for c in SECOPII_ATENEA.columns if c != "id_contrato"]
# rename_map = {c: f"{c} (contratos_electronicos)" for c in atenea_cols}
# SECOPII_ATENEA_ren = SECOPII_ATENEA.rename(columns=rename_map)

# # LEFT JOIN: base = Modificaciones (solo ids presentes en Modificaciones)
# ModificacionesAtenea = SECOPII_Modificaciones.merge(
#     SECOPII_ATENEA_ren, on="id_contrato", how="left"
# )

# print("üîó Filas Modificaciones:", len(SECOPII_Modificaciones))
# print("üîó Filas ATENEA:", len(SECOPII_ATENEA))
# print("‚úÖ Filas resultado (LEFT):", len(ModificacionesAtenea))

# # ================================
# # 2.4 Exportar y descargar
# # ================================
# OUT_MERGED = "ModificacionesAtenea.xlsx"
# ModificacionesAtenea.to_excel(OUT_MERGED, index=False)
# print("üíæ Archivo generado:", OUT_MERGED)

# # Descarga autom√°tica en Colab
# try:
#    from google.colab import files
#    files.download(OUT_MERGED)
# except Exception:
#    pass  # si no est√°s en Colab, simplemente deja el archivo en el directorio de trabajo

## MERGE CON LA BASE TOTAL DE TODOS LOS CONTRATOS DE ATENEA

# ================================================
## MERGE CON LA BASE TOTAL DE TODOS LOS CONTRATOS DE ATENEA
## MERGE DE ATENEA CON MODIFICACIONES (LEFT JOIN)
# ================================================

# Validaciones b√°sicas
assert "SECOPII_Modificaciones" in globals(), "No encuentro SECOPII_Modificaciones en memoria."
assert "SECOPII_ATENEA" in globals(), "No encuentro SECOPII_ATENEA en memoria."
assert "id_contrato" in SECOPII_Modificaciones.columns, "SECOPII_Modificaciones no tiene 'id_contrato'."
assert "id_contrato" in SECOPII_ATENEA.columns, "SECOPII_ATENEA no tiene 'id_contrato'."

# Normaliza la llave en ambos DF
SECOPII_Modificaciones["id_contrato"] = SECOPII_Modificaciones["id_contrato"].astype(str).str.strip()
SECOPII_ATENEA["id_contrato"] = SECOPII_ATENEA["id_contrato"].astype(str).str.strip()

# Renombrar todas las columnas que vienen de Modificaciones (excepto la llave) con "(modificaciones)"
mod_cols = [c for c in SECOPII_Modificaciones.columns if c != "id_contrato"]
rename_map_mod = {c: f"{c} (modificaciones)" for c in mod_cols}
SECOPII_Modificaciones_ren = SECOPII_Modificaciones.rename(columns=rename_map_mod)

# LEFT JOIN: base = ATENEA (LEFT) + Modificaciones (RIGHT)
SECOP_ATENEA_TOTAL = SECOPII_ATENEA.merge(
    SECOPII_Modificaciones_ren,
    on="id_contrato",
    how="left"
)

print("üìä Filas ATENEA:", len(SECOPII_ATENEA))
print("üìä Filas Modificaciones:", len(SECOPII_Modificaciones))
print("üìä Filas resultado (LEFT):", len(SECOP_ATENEA_TOTAL))
SECOP_ATENEA_TOTAL.info()


"""**3. SECOP II - Adiciones**

https://www.datos.gov.co/Gastos-Gubernamentales/SECOP-II-Adiciones/cb9c-h8sn/about_data
"""

# -----------------------------
# 2.2 Descargar Adiciones (cb9c-h8sn) solo para esos id_contrato
# -----------------------------

# ================================
# 3) SECOP II - Adiciones (cb9c-h8sn) solo para los id_contrato ya cargados
# ================================

import os, math, time, random, requests
import pandas as pd
from typing import Optional

# ---------- utilidades SoQL ----------
def soql_quote(value: str) -> str:
    if value is None:
        return "''"
    return "'" + str(value).replace("'", "''").strip() + "'"

def quote_sql_list(values) -> str:
    return ",".join(soql_quote(v) for v in values if v is not None)

# ---------- Config API ----------
BASE_URL   = "https://www.datos.gov.co/resource/cb9c-h8sn.json"  # Adiciones
ID_FIELD   = "id_contrato"
PAGE_SIZE  = 50000
ID_BATCH   = 50            # lotes peque√±os para evitar 414 URI Too Long
PAUSE_S    = 0.25
MAX_RETRY  = 4

# Header con App Token (si lo tienes en el entorno)
headers = {}
_app_token = os.getenv("SODA_APP_TOKEN") or os.getenv("APP_TOKEN") or os.getenv("SOCRATA_APP_TOKEN")
if _app_token:
    headers["X-App-Token"] = _app_token

def fetch_adiciones_for_ids(id_list,
                            id_field: str = ID_FIELD,
                            base_url: str = BASE_URL,
                            page_size: int = PAGE_SIZE,
                            id_batch_size: int = ID_BATCH,
                            session: Optional[requests.Session] = None) -> pd.DataFrame:
    if session is None:
        session = requests.Session()

    # Normaliza ids (no recalculamos √∫nicos; asumimos que 'ids' ya viene)
    id_list = [str(x).strip() for x in list(id_list) if pd.notna(x)]
    if not id_list:
        print("‚ö†Ô∏è La lista de ids est√° vac√≠a. Nada que consultar.")
        return pd.DataFrame(columns=[id_field])

    total_ids     = len(id_list)
    total_batches = math.ceil(total_ids / id_batch_size)
    print(f"üîé Consultando ADICIONES para {total_ids} contratos en {total_batches} lote(s)...")

    all_records = []
    for b in range(total_batches):
        batch = id_list[b*id_batch_size:(b+1)*id_batch_size]
        if not batch:
            continue

        where = f"{id_field} IN ({quote_sql_list(batch)})"

        offset = 0
        while True:
            params = {
                "$select": "*",
                "$where":  where,
                "$order":  f"{id_field} ASC",
                "$limit":  page_size,
                "$offset": offset
            }

            attempt = 0
            while True:
                attempt += 1
                r = session.get(base_url, params=params, headers=headers, timeout=60)
                if r.status_code == 200:
                    try:
                        rows = r.json()
                    except Exception as e:
                        raise RuntimeError(f"Respuesta no JSON. C√≥digo {r.status_code}. URL:\n{r.url}\n\n{r.text[:400]}") from e
                    if isinstance(rows, dict):
                        rows = [rows]
                    break

                if r.status_code in (429, 500, 502, 503, 504) and attempt < MAX_RETRY:
                    wait_s = min(10, 1.5 ** attempt)
                    print(f"‚è≥ {r.status_code} (lote {b+1}/{total_batches}, offset={offset}); "
                          f"reintento {attempt}/{MAX_RETRY} en {wait_s:.1f}s")
                    time.sleep(wait_s)
                    continue

                # Muestra la URL exacta que fall√≥ para depurar
                raise requests.HTTPError(f"HTTP {r.status_code} - {r.text[:300]}\nURL: {r.url}")

            if not rows:
                break  # terminamos este lote

            all_records.extend(rows)
            offset += page_size
            print(f"   Lote {b+1}/{total_batches} +{len(rows)} (acum: {len(all_records)})")
            time.sleep(PAUSE_S)

        time.sleep(random.uniform(0.2, 0.6))  # cortes√≠a entre lotes

    if not all_records:
        print("‚ö†Ô∏è No se recuperaron adiciones para los IDs suministrados.")
        return pd.DataFrame(columns=[id_field])

    df = pd.DataFrame(all_records).drop_duplicates()
    if id_field in df.columns:
        df[id_field] = df[id_field].astype(str).str.strip()
    return df

# ------------ Ejecutar descarga ------------
if "ids" not in globals():
    raise RuntimeError("No encuentro la variable 'ids' en memoria. Ejecuta primero la Secci√≥n 2.")

SECOPII_Adiciones = fetch_adiciones_for_ids(ids)
print(f"üìà Registros de Adiciones descargados: {len(SECOPII_Adiciones):,}")
SECOPII_Adiciones.info()

# # Guarda Excel (opcional)
# OUT_ADIC = "SECOPII_Adiciones.xlsx"
# SECOPII_Adiciones.to_excel(OUT_ADIC, index=False)
# print("üíæ Archivo generado:", OUT_ADIC)

# ========================================
# 2.3 Merge: Adiciones (LEFT) √ó ATENEA (RIGHT)
# ========================================

# # Validaciones b√°sicas
# assert "SECOPII_Adiciones" in globals(), "No encuentro SECOPII_Adiciones en memoria."
# assert "SECOPII_ATENEA" in globals(), "No encuentro SECOPII_ATENEA en memoria."
# assert "id_contrato" in SECOPII_Adiciones.columns, "SECOPII_Adiciones no tiene 'id_contrato'."
# assert "id_contrato" in SECOPII_ATENEA.columns, "SECOPII_ATENEA no tiene 'id_contrato'."

# # Normaliza la llave en ambos DF
# SECOPII_Adiciones["id_contrato"] = SECOPII_Adiciones["id_contrato"].astype(str).str.strip()
# SECOPII_ATENEA["id_contrato"] = SECOPII_ATENEA["id_contrato"].astype(str).str.strip()


# # LEFT JOIN: base = Adiciones (solo ids presentes en Adiciones)
# AdicionesAtenea = SECOPII_Adiciones.merge(
#     SECOPII_ATENEA_ren, on="id_contrato", how="left"
# )

# print("üìä Filas Adiciones:", len(SECOPII_Adiciones))
# print("üìä Filas ATENEA:", len(SECOPII_ATENEA))
# print("üìä Filas resultado (LEFT):", len(AdicionesAtenea))

# ================================
# 2.4 Exportar y descargar AdicionesAtenea
# ================================
# OUT_MERGED = "AdicionesAtenea.xlsx"
# AdicionesAtenea.to_excel(OUT_MERGED, index=False)
# print("üíæ Archivo generado:", OUT_MERGED)

# Descarga autom√°tica en Colab
# try:
#    from google.colab import files
#    files.download(OUT_MERGED)
# except Exception:
#    pass  # si no est√°s en Colab, simplemente deja el archivo en el directorio de trabajo

## MERGE CON LA BASE TOTAL DE TODOS LOS CONTRATOS DE ATENEA
## MERGE DE ATENEA CON ADICIONES (LEFT JOIN)
# ================================================
## MERGE CON LA BASE TOTAL DE TODOS LOS CONTRATOS DE ATENEA + ADICIONES (LEFT JOIN)
# ================================================

# Validaciones b√°sicas
assert "SECOPII_Adiciones" in globals(), "No encuentro SECOPII_Adiciones en memoria."
assert "SECOP_ATENEA_TOTAL" in globals(), "No encuentro SECOP_ATENEA_TOTAL en memoria."
assert "id_contrato" in SECOPII_Adiciones.columns, "SECOPII_Adiciones no tiene 'id_contrato'."
assert "id_contrato" in SECOP_ATENEA_TOTAL.columns, "SECOP_ATENEA_TOTAL no tiene 'id_contrato'."

# Normaliza la llave en ambos DF
SECOPII_Adiciones["id_contrato"] = SECOPII_Adiciones["id_contrato"].astype(str).str.strip()
SECOP_ATENEA_TOTAL["id_contrato"] = SECOP_ATENEA_TOTAL["id_contrato"].astype(str).str.strip()

# Renombrar todas las columnas que vienen de Adiciones (excepto la llave) con "(adiciones)"
adic_cols = [c for c in SECOPII_Adiciones.columns if c != "id_contrato"]
rename_map_adic = {c: f"{c} (adiciones)" for c in adic_cols}
SECOPII_Adiciones_ren = SECOPII_Adiciones.rename(columns=rename_map_adic)

# LEFT JOIN: base = SECOP_ATENEA_TOTAL (LEFT) + Adiciones (RIGHT)
SECOP_ATENEA_TOTAL = SECOP_ATENEA_TOTAL.merge(
    SECOPII_Adiciones_ren,
    on="id_contrato",
    how="left"
)

print("üìä Filas SECOP_ATENEA_TOTAL:", len(SECOP_ATENEA_TOTAL))
print("üìä Filas Adiciones:", len(SECOPII_Adiciones))
print("üìä Filas resultado (LEFT):", len(SECOP_ATENEA_TOTAL))
SECOP_ATENEA_TOTAL.info()


"""**4. SECOP II - Suspensiones de Contratos**

https://www.datos.gov.co/Gastos-Gubernamentales/SECOP-II-Suspensiones-de-Contratos/u99c-7mfm/about_data

https://www.datos.gov.co/resource/u99c-7mfm.json
"""

# ================================
# 4) SECOP II - Suspensiones (u99c-7mfm) solo para los id_contrato ya cargados
# ================================

import os, math, time, random, requests
import pandas as pd
from typing import Optional

# ---------- utilidades SoQL ----------
def soql_quote(value: str) -> str:
    if value is None:
        return "''"
    return "'" + str(value).replace("'", "''").strip() + "'"

def quote_sql_list(values) -> str:
    return ",".join(soql_quote(v) for v in values if v is not None)

# ---------- Config API ----------
BASE_URL   = "https://www.datos.gov.co/resource/u99c-7mfm.json"  # Suspensiones
ID_FIELD   = "id_contrato"
PAGE_SIZE  = 50000
ID_BATCH   = 50            # lotes peque√±os para evitar 414 URI Too Long
PAUSE_S    = 0.25
MAX_RETRY  = 4

# Header con App Token (si lo tienes en el entorno)
headers = {}
_app_token = (
    os.getenv("SODA_APP_TOKEN")
    or os.getenv("APP_TOKEN")
    or os.getenv("SOCRATA_APP_TOKEN")
)
if _app_token:
    headers["X-App-Token"] = _app_token

def fetch_suspensiones_for_ids(id_list,
                               id_field: str = ID_FIELD,
                               base_url: str = BASE_URL,
                               page_size: int = PAGE_SIZE,
                               id_batch_size: int = ID_BATCH,
                               session: Optional[requests.Session] = None) -> pd.DataFrame:
    if session is None:
        session = requests.Session()

    # Normaliza ids
    id_list = [str(x).strip() for x in list(id_list) if pd.notna(x)]
    if not id_list:
        print("‚ö†Ô∏è La lista de ids est√° vac√≠a. Nada que consultar.")
        return pd.DataFrame(columns=[id_field])

    total_ids     = len(id_list)
    total_batches = math.ceil(total_ids / id_batch_size)
    print(f"üîé Consultando SUSPENSIONES para {total_ids} contratos en {total_batches} lote(s)...")

    all_records = []
    for b in range(total_batches):
        batch = id_list[b*id_batch_size:(b+1)*id_batch_size]
        if not batch:
            continue

        where = f"{id_field} IN ({quote_sql_list(batch)})"
        offset = 0

        while True:
            params = {
                "$select": "*",
                "$where":  where,
                "$order":  f"{id_field} ASC",
                "$limit":  page_size,
                "$offset": offset
            }

            attempt = 0
            while True:
                attempt += 1
                r = session.get(base_url, params=params, headers=headers, timeout=60)
                if r.status_code == 200:
                    rows = r.json()
                    if isinstance(rows, dict):
                        rows = [rows]
                    break

                if r.status_code in (429, 500, 502, 503, 504) and attempt < MAX_RETRY:
                    wait_s = min(10, 1.5 ** attempt)
                    print(f"‚è≥ {r.status_code} (lote {b+1}/{total_batches}, offset={offset}); "
                          f"reintento {attempt}/{MAX_RETRY} en {wait_s:.1f}s")
                    time.sleep(wait_s)
                    continue

                raise requests.HTTPError(f"HTTP {r.status_code} - {r.text[:300]}\nURL: {r.url}")

            if not rows:
                break

            all_records.extend(rows)
            offset += page_size
            print(f"   Lote {b+1}/{total_batches} +{len(rows)} (acum: {len(all_records)})")
            time.sleep(PAUSE_S)

        time.sleep(random.uniform(0.2, 0.6))  # cortes√≠a entre lotes

    if not all_records:
        print("‚ö†Ô∏è No se recuperaron suspensiones para los IDs suministrados.")
        return pd.DataFrame(columns=[id_field])

    df = pd.DataFrame(all_records).drop_duplicates()
    if id_field in df.columns:
        df[id_field] = df[id_field].astype(str).str.strip()
    return df

# ------------ Ejecutar descarga ------------
if "ids" not in globals():
    raise RuntimeError("No encuentro la variable 'ids' en memoria. Ejecuta primero la Secci√≥n 2.")

SECOPII_Suspensiones = fetch_suspensiones_for_ids(ids)
print(f"üìà Registros de Suspensiones descargados: {len(SECOPII_Suspensiones):,}")
SECOPII_Suspensiones.info()

# # Guarda Excel (opcional)
# OUT_SUSP = "SECOPII_Suspensiones.xlsx"
# SECOPII_Suspensiones.to_excel(OUT_SUSP, index=False)
# print("üíæ Archivo generado:", OUT_SUSP)

# ================================
# 2.4 Exportar y descargar Suspenciones
# ================================
# OUT_SUSP = "SECOPII_Suspensiones.xlsx"
# AdicionesAtenea.to_excel(OUT_SUSP, index=False)
# print("üíæ Archivo generado:", OUT_SUSP)

# Descarga autom√°tica en Colab
# try:
#    from google.colab import files
#    files.download(OUT_SUSP)
# except Exception:
#    pass  # si no est√°s en Colab, simplemente deja el archivo en el directorio de trabajo

# ------------ LEFT JOIN con tu base total (opcional) ------------
if "SECOP_ATENEA_TOTAL" in globals():
    assert "id_contrato" in SECOP_ATENEA_TOTAL.columns, "SECOP_ATENEA_TOTAL no tiene 'id_contrato'."

    # Renombrar columnas de Suspensiones (menos la llave) para evitar choques
    susp_cols = [c for c in SECOPII_Suspensiones.columns if c != "id_contrato"]
    SECOPII_Suspensiones_ren = SECOPII_Suspensiones.rename(
        columns={c: f"{c} (suspensiones)" for c in susp_cols}
    )

    SECOP_ATENEA_TOTAL = SECOP_ATENEA_TOTAL.merge(
        SECOPII_Suspensiones_ren, on="id_contrato", how="left"
    )

    print("üìä Filas SECOP_ATENEA_TOTAL:", len(SECOP_ATENEA_TOTAL))
    print("üìä Filas Suspensiones:", len(SECOPII_Suspensiones))
    print("üìä Filas resultado (LEFT):", len(SECOP_ATENEA_TOTAL))

    # OUT_RES_SUSP = "SECOP_ATENEA_TOTAL.xlsx"
    # SECOP_ATENEA_TOTAL.to_excel(OUT_RES_SUSP, index=False)
    # print("üíæ Archivo generado:", OUT_RES_SUSP)

    # Descarga autom√°tica si est√°s en Colab
    ## try:
    ##     from google.colab import files
    ##     files.download(OUT_RES_SUSP)
    ## except Exception:
    ##     pass

## else:
   ##  print("‚ÑπÔ∏è No encontr√© SECOP_ATENEA_TOTAL. Se omiti√≥ el merge opcional.")

SECOP_ATENEA_TOTAL.info()
SECOP_ATENEA_TOTAL["id_contrato"]

"""**4. SECOP II - PAA Detalles**

https://www.datos.gov.co/api/odata/v4/9sue-ezhx
"""

# ---------------------------
# 1) Configuraci√≥n de la API
# ---------------------------
BASE_URL = "https://www.datos.gov.co/resource/9sue-ezhx.json"

# Nombre exacto de la entidad a filtrar
entidad = "AGENCIA DISTRITAL PARA LA EDUCACI√ìN SUPERIOR LA CIENCIA Y LA TECNOLOG√çA ATENEA"

# ---------------------------
# 2) Consulta con filtro SoQL
# ---------------------------
# OJO: las cadenas en SoQL van entre comillas simples
params = {
    "$where": f"nombre_entidad='{entidad}'",
    "$limit": 50000   # ajustar si hay m√°s registros
}

response = requests.get(BASE_URL, params=params)
response.raise_for_status()  # lanza error si la API falla

# ---------------------------
# 3) Convertir a DataFrame
# ---------------------------
data = response.json()
df = pd.DataFrame(data)

PAA_DETALLES_ATENEA = df
print(f"Registros descargados: {len(PAA_DETALLES_ATENEA)}")
print(PAA_DETALLES_ATENEA.head())
PAA_DETALLES_ATENEA.info()

# ---------------------------
# 4) Guardar en Excel
# ---------------------------
outfile = "C:/Users/Natalia/Downloads/Atenea/PAA_DETALLES_ATENEA.xlsx"
PAA_DETALLES_ATENEA.to_excel(outfile, index=False, engine="openpyxl")
print(f"Archivo exportado: {outfile}")

# # ================================
# #Exportar y descargar PAA
# # ================================
# OUT_PAA = "PAA_DETALLES_ATENEA.xlsx"

# # Exportar a Excel
# df.to_excel(OUT_PAA, index=False, engine="openpyxl")
# print("üíæ Archivo generado:", OUT_PAA)

# # Descarga autom√°tica en Colab
# # try:
# #    from google.colab import files
# #    files.download(OUT_PAA)
# #except Exception:
#     # Si no est√°s en Colab, simplemente deja el archivo en el directorio de trabajo
# #    pass

# import pandas as pd

# # Leer archivo Excel en un DataFrame
# PAA_DETALLES_ATENEA = pd.read_excel("PAA_DETALLES_ATENEA.xlsx")

#-------------------------------
### **8. Join con SECOP_total**
#-------------------------------

# Crear ID para unir SECOP_total y PAA (revisar). ID EN BASE DE PAA
PAA_DETALLES_ATENEA["ID_PAA_SECOP"] = (
    PAA_DETALLES_ATENEA["descripcion"].astype(str) + " " +
    PAA_DETALLES_ATENEA["procesos_relacionados"].astype(str)
)
PAA_DETALLES_ATENEA["ID_PAA_SECOP"]

# Revisar las primeras filas
print(PAA_DETALLES_ATENEA[["descripcion", "procesos_relacionados", "ID_PAA_SECOP"]].head())

print(SECOP_ATENEA_TOTAL.columns.tolist())

# Crear ID para unir SECOP_total y PAA (revisar). ID EN BASE DE SECOP_TOTAL
SECOP_ATENEA_TOTAL["ID_PAA_SECOP"] = SECOP_ATENEA_TOTAL['descripcion_del_proceso (Contratos_electronicos)'] + " " + SECOP_ATENEA_TOTAL['referencia_del_contrato (Contratos_electronicos)']

# ==== LEFT JOIN aproximado por ID_PAA_SECOP (SECOP_ATENEA_TOTAL ‚Üê PAA_DETALLES_ATENEA) ====
import re, unicodedata, numpy as np, pandas as pd
from pathlib import Path
from rapidfuzz import process, fuzz

# --- RapidFuzz ---
# try:
#     from rapidfuzz import process, fuzz
# except Exception:
#     import sys, subprocess
#     subprocess.run([sys.executable, "-m", "pip", "install", "-q", "rapidfuzz"])
#     from rapidfuzz import process, fuzz

# ==================== Par√°metros ====================
UMBRAL   = 85     # 0-100: ajusta la exigencia del emparejamiento

# ==================== Helpers ====================
def _norm_txt(s: object) -> str:
    """Normaliza: min√∫sculas, sin tildes, solo [a-z0-9], colapsa espacios."""
    if pd.isna(s): return ""
    s = str(s).strip().lower()
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")  # quita tildes
    s = re.sub(r"[^a-z0-9\s]", " ", s)  # quita signos, guiones, etc.
    s = re.sub(r"\s+", " ", s).strip()
    return s

# ==================== 1) Preparaci√≥n ====================
# Limpia encabezados por si acaso
SECOP_ATENEA_TOTAL.columns = SECOP_ATENEA_TOTAL.columns.str.strip()
PAA_DETALLES_ATENEA.columns = PAA_DETALLES_ATENEA.columns.str.strip()

# Trabaja sobre copias
left  = SECOP_ATENEA_TOTAL.copy()
right = PAA_DETALLES_ATENEA.copy()

# Normaliza llaves (mismo nombre en ambos DFs)
left["_key_norm"]  = left["ID_PAA_SECOP"].map(_norm_txt)
right["_key_norm"] = right["ID_PAA_SECOP"].map(_norm_txt)

# Universo de candidatos (lista de claves normalizadas del PAA)
choices = right["_key_norm"].astype(str).tolist()

# ==================== 2) Fuzzy matching (solo aproximado) ====================
best_idx = []   # √≠ndice de la fila en 'right' elegida para cada fila del izquierdo
best_scr = []   # puntaje de similitud (0-100)

for s in left["_key_norm"].astype(str):
    if not s:
        best_idx.append(np.nan); best_scr.append(np.nan); continue
    # token_set_ratio es robusto ante palabras reordenadas/ruido
    m = process.extractOne(s, choices, scorer=fuzz.token_set_ratio, score_cutoff=0)
    if not m:
        best_idx.append(np.nan); best_scr.append(np.nan)
    else:
        _, score, idx = m
        if score >= UMBRAL:
            best_idx.append(int(idx)); best_scr.append(float(score))
        else:
            best_idx.append(np.nan);   best_scr.append(float(score))

# Puntaje al DF izquierdo
left["PAA_matchingScore"] = pd.Series(best_scr, dtype="float").round(2)
left["PAA_matchingScore"].describe()

left.shape
left["PAA_matchingScore"].isnull().sum()

# ==================== 3) Left join: traer columnas del PAA ====================
# Tomamos todas las columnas de PAA excepto la auxiliar
cols_right = [c for c in right.columns if c != "_key_norm"]

# Construye DataFrame alineado al √≠ndice del izquierdo
paa_take = pd.DataFrame(index=left.index)
mapped   = pd.Series(best_idx, index=left.index, dtype="float")
valid    = mapped.dropna().astype(int)

if len(valid) > 0:
    right_sel = right.iloc[valid.values][cols_right].copy()
    right_sel.index = valid.index  # alinea por √≠ndice del izquierdo
    for c in cols_right:
        paa_take[f"PAA::{c}"] = right_sel.reindex(left.index)[c]

# Combina resultado
merged = pd.concat([left.drop(columns=["_key_norm"], errors="ignore"), paa_take], axis=1)

# ==================== 4) Actualiza variable y exporta ====================
SECOP_ATENEA_TOTAL = merged  # deja el resultado final en la misma variable
SECOP_ATENEA_TOTAL.info()
SECOP_ATENEA_TOTAL.to_excel("C:/Users/Natalia/Downloads/Atenea/SECOP_ATENEA_TOTAL.xlsx", index=False, engine="openpyxl")


# -------------------------------------------------------------

# preprocesar la variable "PAA::descripcion" para sacar "N√∫mero_PAA_descripci√≥n" y "CODIGO_Dependencia"

# 1) Localizar con tolerancia la columna "PAA::descripcion"
col = "PAA::descripcion"
if col not in SECOP_ATENEA_TOTAL.columns:
    lookup = {c.strip().lower(): c for c in SECOP_ATENEA_TOTAL.columns}
    if "paa::descripcion" in lookup:
        col = lookup["paa::descripcion"]
    else:
        raise KeyError(f"No encuentro la columna '{col}' en SECOP_ATENEA_TOTAL.")

# 2) RegEx:
#    - ^\s*(\d+)  -> primeros d√≠gitos del inicio del texto
#    - \s+        -> separador
#    - ([A-Z√Å√â√ç√ì√ö√ë]{2,5}) -> siglas (2‚Äì5 letras) inmediatamente despu√©s
pat = re.compile(r'^\s*(\d+)\s+([A-Z√Å√â√ç√ì√ö√ë]{2,5})\b', re.IGNORECASE)

# 3) Extraer n√∫mero y siglas
extra = SECOP_ATENEA_TOTAL[col].astype(str).str.extract(pat, expand=True)
SECOP_ATENEA_TOTAL["N√∫mero_PAA_descripci√≥n"] = extra[0].astype("string")
SECOP_ATENEA_TOTAL["CODIGO_Dependencia"]      = extra[1].str.upper().astype("string")

# 4) Tercera variable: "ID_PAA _GA" = n√∫mero + espacio + c√≥digo
num = SECOP_ATENEA_TOTAL["N√∫mero_PAA_descripci√≥n"].fillna("").str.strip()
cod = SECOP_ATENEA_TOTAL["CODIGO_Dependencia"].fillna("").str.strip()
SECOP_ATENEA_TOTAL["ID_PAA _GA"] = np.where((num != "") & (cod != ""), num + " " + cod, "")

# Vista r√°pida
SECOP_ATENEA_TOTAL[[col, "N√∫mero_PAA_descripci√≥n", "CODIGO_Dependencia", "ID_PAA _GA"]].head()

# Derivar la "Dependencia" del Diccionario_Dependencia que creamos al inicio del c√≥digo

# 1) Normalizar llaves en ambos DF
Diccionario_Dependencia = Diccionario_Dependencia.drop_duplicates("CODIGO_ID").copy()
Diccionario_Dependencia["CODIGO_ID"] = (
    Diccionario_Dependencia["CODIGO_ID"].astype(str).str.strip().str.upper()
)

SECOP_ATENEA_TOTAL["CODIGO_Dependencia"] = (
    SECOP_ATENEA_TOTAL["CODIGO_Dependencia"].astype(str).str.strip().str.upper()
)

# 2) Construir el "diccionario" y mapear (BUSCARV)
mapa_dep = dict(
    zip(Diccionario_Dependencia["CODIGO_ID"], Diccionario_Dependencia["DEPENDENCIA"])
)

SECOP_ATENEA_TOTAL["DEPENDENCIA SOLICITANTE::paa"] = (
    SECOP_ATENEA_TOTAL["CODIGO_Dependencia"].map(mapa_dep)
)

# (Opcional) Ver c√≥digos que no encontraron coincidencia en el diccionario
faltantes = sorted(
    set(SECOP_ATENEA_TOTAL["CODIGO_Dependencia"].dropna()) - set(mapa_dep.keys())
)
print("C√≥digos sin mapeo:", faltantes)

# (Opcional) vista r√°pida
SECOP_ATENEA_TOTAL[
    ["PAA::descripcion", "N√∫mero_PAA_descripci√≥n", "CODIGO_Dependencia", "ID_PAA _GA", "DEPENDENCIA SOLICITANTE::paa"]
].head()

"""**TRANSFORMACIONES Y VARIABLES INFERIDAS**"""

listado_variables = SECOP_ATENEA_TOTAL.columns.tolist()
listado_variables

# Variable a√±o
# Calculo: se extrae el a√±o de la variable "referencia_del_contrato (Contratos_electronicos)_SecopDatosAbiertos"


# Nombre EXACTO de la columna de referencia (aj√∫stalo si difiere)
col_ref =  'referencia_del_contrato (Contratos_electronicos)'

# 1) Extrae los 4 d√≠gitos finales si existen
anio = (
    SECOP_ATENEA_TOTAL[col_ref]
      .astype(str)
      .str.strip()
      .str.extract(r'(\d{4})\s*$')[0]   # toma la 1¬™ captura
)

# 2) Convierte a num√©rico; lo que no cumpla queda en NaN
anio = pd.to_numeric(anio, errors="coerce")

# 3) Usa entero ‚Äúnullable‚Äù para permitir NaN (en vez de astype(int))
SECOP_ATENEA_TOTAL["A√ëO_INFERIDO"] = anio.astype("Int64")


# üíæ Mostrar resultado
print(SECOP_ATENEA_TOTAL["A√ëO_INFERIDO"])

"""TIPO_PERSONA_INFERIDO

Reglas de inferencia:

- Si tipodocproveedor contiene "C√âDULA" ‚Üí Natural
- Si tipodocproveedor contiene "NIT" ‚Üí Jur√≠dica
- Si el nombre del proveedor contiene palabras clave como "S.A", "SAS", "LTDA", "ASOCIACI√ìN", "UNIVERSIDAD", "EMPRESA", "COOPERATIVA" ‚Üí Jur√≠dica
"""


# Columnas relevantes (ajusta si difieren)
col_doc  =  'tipodocproveedor (Contratos_electronicos)'
col_nom  =  'proveedor_adjudicado (Contratos_electronicos)'

# ==========================================
# 2) Normalizaci√≥n ligera
# ==========================================
def limpiar_txt(s):
    if pd.isna(s):
        return ""
    s = str(s).upper().strip()
    s = (s.replace("√Å","A").replace("√â","E").replace("√ç","I")
           .replace("√ì","O").replace("√ö","U"))
    return s

SECOP_ATENEA_TOTAL[col_doc] = SECOP_ATENEA_TOTAL[col_doc].apply(limpiar_txt)
SECOP_ATENEA_TOTAL[col_nom] = SECOP_ATENEA_TOTAL[col_nom].apply(limpiar_txt)

# Palabras clave para PERSONA JUR√çDICA en el nombre del proveedor
PATRONES_JURIDICA = r"\b(SAS|S\.A|S\. A|LTDA|ASOCIACION|UNIVERSIDAD|EMPRESA|COOPERATIVA|CORPORACION|CONSORCIO|FUNDACION)\b"

# ==========================================
# 3) Reglas de inferencia (sin default a Natural)
# ==========================================
def inferir_tipo(row):
    doc = row[col_doc]
    nom = row[col_nom]

    # Regla por tipo de documento
    if "CEDULA" in doc:
        return "Natural"
    if "NIT" in doc:
        return "Jur√≠dica"

    # Regla por nombre del proveedor
    if re.search(PATRONES_JURIDICA, nom):
        return "Jur√≠dica"

    # En caso contrario, dejar vac√≠o
    return pd.NA

SECOP_ATENEA_TOTAL["TIPO_PERSONA_INFERIDO"] = SECOP_ATENEA_TOTAL.apply(inferir_tipo, axis=1)


# üíæ Mostrar resultado
print(SECOP_ATENEA_TOTAL["TIPO_PERSONA_INFERIDO"])

"""SUSPENSI√ìN_INFERIDO

"tipo (suspensiones)_SecopDatosAbiertos" == "Suspension"
"""

SECOP_ATENEA_TOTAL['SUSPENSI√ìN_INFERIDO'] = SECOP_ATENEA_TOTAL['tipo (suspensiones)'].apply(
    lambda x: "1 SI" if str(x).strip().upper() == "SUSPENSION" else "2 NO"
)


# üíæ Mostrar resultado
print(SECOP_ATENEA_TOTAL["SUSPENSI√ìN_INFERIDO"])



#######------------------------------------------------##########

"""PLAZO DE EJECUCI√ìN EN MESES (INICIAL)

Formula:
Calcular n√∫mer de meses entre:

"fecha_de_fin_del_contrato (Contratos_electronicos)_SecopDatosAbiertos" - "fecha_de_firma (Contratos_electronicos)_SecopDatosAbiertos"
"""

from dateutil.relativedelta import relativedelta

# ==== 1) Nombres de columnas originales (NO se modifican) ====
col_firma_raw =  'fecha_de_firma (Contratos_electronicos)'
col_fin_raw   =  'fecha_de_fin_del_contrato (Contratos_electronicos)'

# Nombres de columnas parseadas (nuevas)
col_firma_dt = col_firma_raw + " __dt"
col_fin_dt   = col_fin_raw   + " __dt"

# ==== 2) Funci√≥n robusta para parsear fechas sin alterar la original ====
def parse_fecha_robusta(val):
    """
    Intenta convertir 'val' a datetime manejando:
    - ISO 8601 (yyyy-mm-dd, yyyy-mm-ddTHH:MM:SS)
    - Formatos dd/mm/yyyy o dd-mm-yyyy (dayfirst)
    - N√∫meros de serie de Excel (fechas como 45237)
    - Cadenas con ruido/espacios
    Devuelve pd.NaT si no se puede.
    """
    if pd.isna(val):
        return pd.NaT

    # 1) N√∫meros de serie de Excel (int/float no-truncado)
    #    Regla: valores num√©ricos razonables (>= 59 para evitar 1900-02-29 bug)
    try:
        if isinstance(val, (int, float)) and not isinstance(val, bool):
            # algunos archivos traen la fecha como 5.2024E5 -> no aplicar si es muy grande
            if 50 <= float(val) <= 100000:  # rango prudente de series
                return pd.to_datetime(val, origin='1899-12-30', unit='D', errors='coerce')
    except Exception:
        pass

    # 2) Texto
    s = str(val).strip()
    if not s:
        return pd.NaT

    # Limpieza b√°sica
    s = s.replace("\u200b", "").strip()

    # 2.1) ISO o con 'T'
    try:
        if re.search(r"\d{4}-\d{2}-\d{2}", s):
            dt = pd.to_datetime(s, errors='coerce', utc=False)
            if not pd.isna(dt):
                return dt
    except Exception:
        pass

    # 2.2) dd/mm/yyyy o dd-mm-yyyy (forzar dayfirst)
    try:
        if re.search(r"\b\d{1,2}[/-]\d{1,2}[/-]\d{2,4}\b", s):
            dt = pd.to_datetime(s, errors='coerce', dayfirst=True)
            if not pd.isna(dt):
                return dt
    except Exception:
        pass

    # 2.3) Intento general final (pandas heur√≠stico con dos variantes)
    for dayfirst in (True, False):
        try:
            dt = pd.to_datetime(s, errors='coerce', dayfirst=dayfirst)
            if not pd.isna(dt):
                return dt
        except Exception:
            continue

    return pd.NaT

# ==== 3) Crear columnas nuevas parseadas (originales intactas) ====
SECOP_ATENEA_TOTAL[col_firma_dt] = SECOP_ATENEA_TOTAL[col_firma_raw].apply(parse_fecha_robusta)
SECOP_ATENEA_TOTAL[col_fin_dt]   = SECOP_ATENEA_TOTAL[col_fin_raw].apply(parse_fecha_robusta)

# ==== 4) Calcular meses (con decimales) usando las columnas parseadas ====
def meses_entre(f_inicio, f_fin):
    if pd.isna(f_inicio) or pd.isna(f_fin):
        return np.nan
    rd = relativedelta(f_fin, f_inicio)
    # meses completos + fracci√≥n aproximada por d√≠as/30
    return rd.years * 12 + rd.months + (rd.days / 30)

SECOP_ATENEA_TOTAL["PLAZO DE EJECUCI√ìN EN MESES (INICIAL)_inferido"] = (
    SECOP_ATENEA_TOTAL.apply(
        lambda r: meses_entre(r[col_firma_dt], r[col_fin_dt]), axis=1
    ).round(2)
)

# ==== 5) Diagn√≥stico √∫til ====
print("üîé Diagn√≥stico de parseo:")
for c_raw, c_dt in [(col_firma_raw, col_firma_dt), (col_fin_raw, col_fin_dt)]:
    total = len(SECOP_ATENEA_TOTAL)
    ok = SECOP_ATENEA_TOTAL[c_dt].notna().sum()
    print(f"  {c_raw} -> {c_dt}: parseadas {ok}/{total} ({ok/total:.1%})")

print("\nüìä Vista previa:")
print(
    SECOP_ATENEA_TOTAL[[col_firma_raw, col_firma_dt, col_fin_raw, col_fin_dt,
                        "PLAZO DE EJECUCI√ìN EN MESES (INICIAL)_inferido"]]
        .head(12)
        .to_string(index=False)
)

"""PLAZO DE EJECUCI√ìN FINAL DEL CONTRATO (D√çAS)_inferido"""

# ==== 4) Calcular diferencia en d√≠as (no en meses) ====


def dias_entre(f_inicio, f_fin):
    if pd.isna(f_inicio) or pd.isna(f_fin):
        return np.nan
    return (f_fin - f_inicio).days  # devuelve n√∫mero entero de d√≠as

SECOP_ATENEA_TOTAL["PLAZO DE EJECUCI√ìN FINAL DEL CONTRATO (D√çAS)_inferido"] = SECOP_ATENEA_TOTAL.apply(
    lambda r: dias_entre(r[col_firma_dt], r[col_fin_dt]), axis=1
)



# ==== 5) Diagn√≥stico √∫til ====
print("üîé Diagn√≥stico de parseo:")
for c_raw, c_dt in [(col_firma_raw, col_firma_dt), (col_fin_raw, col_fin_dt)]:
    total = len(SECOP_ATENEA_TOTAL)
    ok = SECOP_ATENEA_TOTAL[c_dt].notna().sum()
    print(f"  {c_raw} -> {c_dt}: parseadas {ok}/{total} ({ok/total:.1%})")

print("\nüìä Vista previa del c√°lculo (primeras filas):")
print(
    SECOP_ATENEA_TOTAL[
        [col_firma_raw, col_firma_dt, col_fin_raw, col_fin_dt,
         "PLAZO DE EJECUCI√ìN FINAL DEL CONTRATO (D√çAS)_inferido"]
    ].head(12).to_string(index=False)
)

"""%avancePlazo_Inferido"""


# ================================
# 1Ô∏è‚É£ Columnas base
# ================================
col_firma_dt = 'fecha_de_firma (Contratos_electronicos) __dt'
col_plazo_dias = 'PLAZO DE EJECUCI√ìN FINAL DEL CONTRATO (D√çAS)_inferido'

# ================================
# 2Ô∏è‚É£ Calcular d√≠as transcurridos desde la firma hasta hoy
# ================================
hoy = pd.Timestamp(datetime.now().date())

# Si la columna de firma ya existe en formato datetime, perfecto.
# Si no, intenta parsearla de nuevo por seguridad
if col_firma_dt not in SECOP_ATENEA_TOTAL.columns:
    SECOP_ATENEA_TOTAL[col_firma_dt] = pd.to_datetime(
        SECOP_ATENEA_TOTAL['fecha_de_firma (Contratos_electronicos)'],
        errors='coerce'
    )

SECOP_ATENEA_TOTAL["DIAS_TRANSCURRIDOS_DESDE_FIRMA"] = (
    (hoy - SECOP_ATENEA_TOTAL[col_firma_dt]).dt.days
)

# ================================
# 3Ô∏è‚É£ Calcular % de avance del plazo
# ================================
SECOP_ATENEA_TOTAL["%avancePlazo_Inferido"] = np.where(
    (SECOP_ATENEA_TOTAL[col_plazo_dias] > 0) & (~SECOP_ATENEA_TOTAL[col_plazo_dias].isna()),
    (SECOP_ATENEA_TOTAL["DIAS_TRANSCURRIDOS_DESDE_FIRMA"] / SECOP_ATENEA_TOTAL[col_plazo_dias]) * 100,
    np.nan
)

# Limitar a m√°ximo 100% (opcional)
SECOP_ATENEA_TOTAL["%avancePlazo_Inferido"] = SECOP_ATENEA_TOTAL["%avancePlazo_Inferido"].clip(upper=100)

# ================================
# 4Ô∏è‚É£ Vista previa de resultados
# ================================
print("üìä Vista previa de avance del plazo:")
print(
    SECOP_ATENEA_TOTAL[
        ["fecha_de_firma (Contratos_electronicos)",
         col_firma_dt,
         col_plazo_dias,
         "DIAS_TRANSCURRIDOS_DESDE_FIRMA",
         "%avancePlazo_Inferido"]
    ].head(10).to_string(index=False)
)

# ================================
# 5Ô∏è‚É£ (Opcional) Guardar resultado
# ================================
# SECOP_ATENEA_TOTAL.to_excel("SECOP_ATENEA_TOTAL_avancePlazo.xlsx", index=False)


## -----------------------------------------------------------#

"""TERMINACI√ìN ANTICIPADA_inferido

"proposito_modificacion (modificaciones)_SecopDatosAbiertos" contiene  "TERMINAR ANTICIPADAMENTE" or "TERMINACI√ìN ANTICIPADA"


OR
"descripcion (adiciones)_SecopDatosAbiertos" contiene  "TERMINAR ANTICIPADAMENTE" or "TERMINACI√ìN ANTICIPADA"
"""

# ‚úÖ Columnas de origen (ajusta si el nombre exacto difiere en tu base)
COL_MOD =  'proposito_modificacion (modificaciones)'
COL_ADI =  'descripcion (adiciones)'

# --- Normalizador: quita tildes, pasa a min√∫sculas y compacta espacios ---
def _norm(s):
    if pd.isna(s):
        return ""
    s = str(s).lower().strip()
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")  # sin tildes
    s = re.sub(r"\s+", " ", s)
    return s

# --- Regex amplio para ‚Äúterminaci√≥n anticipada‚Äù y variantes ---
# Cubre: "terminacion anticipada", "terminar anticipadamente",
# "dar por terminado anticipadamente", "terminar de manera anticipada", etc.
PATRON_TERMINACION_ANT = re.compile(
    r"\b("                                 # inicio grupo general
    r"(dar\s+por\s+terminad\w+)\s+(de\s+manera\s+)?anticipad\w*"   # dar por terminado ... anticipad*
    r"|termin(ar|ad[oa]?|acion)\s+(de\s+manera\s+)?anticipad\w*"   # terminar/terminada/terminacion ... anticipad*
    r")\b",
    re.IGNORECASE
)

def _es_terminacion_ant(texto):
    s = _norm(texto)
    if not s:
        return False
    return bool(PATRON_TERMINACION_ANT.search(s))

# --- Aplicar sobre ambas columnas y construir la variable inferida ---
mask_mod = SECOP_ATENEA_TOTAL.get(COL_MOD).apply(_es_terminacion_ant) if COL_MOD in SECOP_ATENEA_TOTAL.columns else False
mask_adi = SECOP_ATENEA_TOTAL.get(COL_ADI).apply(_es_terminacion_ant) if COL_ADI in SECOP_ATENEA_TOTAL.columns else False

mask_total = (mask_mod.astype(bool)) | (mask_adi.astype(bool))

SECOP_ATENEA_TOTAL["TERMINACI√ìN ANTICIPADA_inferido"] = np.where(mask_total, "1 SI", "2 NO")

# üîé Diagn√≥stico opcional
print("üìä Resumen TERMINACI√ìN ANTICIPADA_inferido")
print(SECOP_ATENEA_TOTAL["TERMINACI√ìN ANTICIPADA_inferido"].value_counts(dropna=False))

# (Opcional) Ver ejemplos positivos para validar
ejemplos = SECOP_ATENEA_TOTAL.loc[mask_total, [COL_MOD, COL_ADI]].head(10)
print("\nüîé Ejemplos que activaron la regla (primeros 10):")
print(ejemplos.to_string(index=False))

"""OBSERVACIONES_inferido"""

# üîπ Nombres de las columnas originales
col_mod =  'proposito_modificacion (modificaciones)'
col_adi =  'descripcion (adiciones)'

# üîπ Crear nueva variable OBSERVACIONES_inferido
def combinar_observaciones(mod, adi):
    mod = str(mod).strip() if pd.notna(mod) else ""
    adi = str(adi).strip() if pd.notna(adi) else ""

    if mod and adi:
        return f"{mod} | {adi}"
    elif mod:
        return mod
    elif adi:
        return adi
    else:
        return np.nan

SECOP_ATENEA_TOTAL["OBSERVACIONES_inferido"] = SECOP_ATENEA_TOTAL.apply(
    lambda r: combinar_observaciones(r.get(col_mod), r.get(col_adi)), axis=1
)

# üîé Vista previa
print("üìã Vista previa de OBSERVACIONES_inferido:")
print(
    SECOP_ATENEA_TOTAL[
        [col_mod, col_adi, "OBSERVACIONES_inferido"]
    ].head(10).to_string(index=False)
)

# üíæ (Opcional) Guardar resultado
# SECOP_ATENEA_TOTAL.to_excel("SECOP_ATENEA_TOTAL_ObservacionesInferido.xlsx", index=False)

"""CESI√ìN_inferido"""

# ===============================================
# 1Ô∏è‚É£ Nombres de columnas usadas en la condici√≥n
# ===============================================
col_estado =  'estado_contrato (Contratos_electronicos)'
col_tipo_adi =  'tipo (adiciones)'
col_proposito_mod =  'proposito_modificacion (modificaciones)'
col_desc_adi =  'descripcion (adiciones)'

# ===============================================
# 2Ô∏è‚É£ Funci√≥n para normalizar texto
#    (quita tildes, convierte a min√∫sculas, quita espacios)
# ===============================================
def normalizar_texto(s):
    if pd.isna(s):
        return ""
    s = str(s).lower().strip()
    s = unicodedata.normalize("NFD", s)
    s = "".join(ch for ch in s if unicodedata.category(ch) != "Mn")  # quitar tildes
    return s

# ===============================================
# 3Ô∏è‚É£ Aplicar la regla de inferencia
# ===============================================
def es_cesion(row):
    estado = normalizar_texto(row.get(col_estado, ""))
    tipo_adi = normalizar_texto(row.get(col_tipo_adi, ""))
    proposito = normalizar_texto(row.get(col_proposito_mod, ""))
    descripcion = normalizar_texto(row.get(col_desc_adi, ""))

    # Condiciones l√≥gicas seg√∫n la f√≥rmula
    cond1 = estado == "cedido"
    cond2 = tipo_adi == "cesion"
    cond3 = bool(re.search(r"\bcesion\b", proposito))
    cond4 = bool(re.search(r"\bcesion\b", descripcion))

    if cond1 or cond2 or cond3 or cond4:
        return "SI"
    else:
        return "NO"

SECOP_ATENEA_TOTAL["CESI√ìN_inferido"] = SECOP_ATENEA_TOTAL.apply(es_cesion, axis=1)

# ===============================================
# 4Ô∏è‚É£ Validaci√≥n r√°pida
# ===============================================
conteo = SECOP_ATENEA_TOTAL["CESI√ìN_inferido"].value_counts(dropna=False)
print("üìä Conteo de CESI√ìN_inferido:")
print(conteo)

# Mostrar ejemplos donde se detect√≥ "SI"
print("\nüîé Ejemplos detectados como CESI√ìN:")
print(
    SECOP_ATENEA_TOTAL.loc[SECOP_ATENEA_TOTAL["CESI√ìN_inferido"] == "SI",
                           [col_estado, col_tipo_adi, col_proposito_mod, col_desc_adi, "CESI√ìN_inferido"]
                          ].head(10).to_string(index=False)
)



# -------------------------------------------------------------------------- #

"""**Formula DIAN**

https://es.wikipedia.org/wiki/N%C3%BAmero_de_Identificaci%C3%B3n_Tributaria_(Colombia)

https://www.consultorcontable.com/digito-de-verificacion-de-nit

"""


# --- Config ---
COL = 'documento_proveedor (Contratos_electronicos)'


# 1) Limpiar y dejar solo los d√≠gitos del NIT (sin DV)
def limpiar_nit_base(x):
    """
    Recibe cualquier cosa (str, n√∫mero, con o sin guion) y retorna solo d√≠gitos del NIT base.
    Si viene con guion (e.g., '900123456-7'), se queda con la parte izquierda.
    """
    if pd.isna(x):
        return np.nan
    s = str(x).strip()
    # Si viene con DV separado por guion, usar solo la parte izquierda
    if '-' in s:
        s = s.split('-', 1)[0]
    # Quitar todo lo que no sea d√≠gito
    s = re.sub(r'\D', '', s)
    return np.nan if s == '' else s

SECOP_ATENEA_TOTAL['nit_base'] = SECOP_ATENEA_TOTAL[COL].apply(limpiar_nit_base)

# 2) C√°lculo del DV DIAN (ponderaciones oficiales)
# Ponderaciones desde la derecha: 3,7,13,17,19,23,29,37,41,43,47,53,59,67,71
WEIGHTS = [3,7,13,17,19,23,29,37,41,43,47,53,59,67,71]

def dv_dian(nit_base):
    """
    Calcula el d√≠gito de verificaci√≥n DIAN del NIT base (sin DV).
    Regla: r = suma(d_i * w_i) % 11; DV = r si r in {0,1} else 11 - r
    """
    if pd.isna(nit_base):
        return np.nan
    s = str(nit_base)
    # Alinear pesos desde la derecha; si el NIT es m√°s largo que 15, usamos los 15 √∫ltimos d√≠gitos.
    if len(s) > len(WEIGHTS):
        s = s[-len(WEIGHTS):]
    total = 0
    for i, d in enumerate(reversed(s)):
        total += int(d) * WEIGHTS[i]
    r = total % 11
    return r if r in (0, 1) else 11 - r

SECOP_ATENEA_TOTAL['D√≠gitoVerificaci√≥nDIAN_DV'] = SECOP_ATENEA_TOTAL['nit_base'].apply(dv_dian).astype('Int64')

"""**EXPORTAR ARCHIVO FINAL**"""

outfile = "SECOP_ATENEA_TOTAL.xlsx"
SECOP_ATENEA_TOTAL.to_excel(outfile, index=False, engine="openpyxl")

# Exportar base de datos SECOP_ATENEA_TOTAL
OUTFILE = Path("SECOP_ATENEA_TOTAL.xlsx")
SECOP_ATENEA_TOTAL.to_excel(OUTFILE, index=False, engine="openpyxl")
print("üíæ Exportado:", OUTFILE.resolve())


#### ---------------------------------------------------------------###

"""**INDICADORES DE SEGUIMIENTO A LA GESTI√ìN CONTRACTUAL**"""

import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns

# Lista para almacenar resultados
indicadores_resultados = []

df =SECOP_ATENEA_TOTAL

# === Indicador 1: N√∫mero total de contratos adjudicados ===
num_contratos = df["id_contrato"].nunique()
print(f"Indicador 1 - N√∫mero total de contratos adjudicados: {num_contratos}")
indicadores_resultados.append({
    "Indicador": "N√∫mero total de contratos adjudicados",
    "Resultado": num_contratos
})

# === Indicador 2: Valor total contratado ===
col_valor = "valor_del_contrato (Contratos_electronicos)"
df[col_valor] = pd.to_numeric(df[col_valor], errors='coerce').fillna(0)  # Asegura que es num√©rico

valor_total_contratado = df[col_valor].sum()

print(f"Indicador 2 - Valor total contratado: ${valor_total_contratado:,.0f}")

indicadores_resultados.append({
    "Indicador": "Valor total contratado",
    "Resultado": valor_total_contratado
})

# === Indicador 3: Distribuci√≥n por tipo de contrato ===
tipo_col = "tipo_de_contrato (Contratos_electronicos)"
valor_col = "valor_del_contrato (Contratos_electronicos)"

# Asegurar tipo num√©rico
df[valor_col] = pd.to_numeric(df[valor_col], errors='coerce').fillna(0)

# Conteo y suma por tipo de contrato
tipo_contrato_dist = df[tipo_col].value_counts()
tipo_contrato_valores = df.groupby(tipo_col)[valor_col].sum()

# Mostrar en texto
print("Indicador 3 - Distribuci√≥n por tipo de contrato:")
for tipo in tipo_contrato_dist.index:
    cantidad = tipo_contrato_dist[tipo]
    valor = tipo_contrato_valores[tipo]
    print(f" - {tipo}: {cantidad} contratos, por ${valor:,.0f}")

# === Indicador 4: Distribuci√≥n por modalidad de contrataci√≥n ===
modalidad_col = "modalidad_de_contratacion (Contratos_electronicos)"
valor_col = "valor_del_contrato (Contratos_electronicos)"

modalidad_dist = df[modalidad_col].value_counts()
modalidad_valores = df.groupby(modalidad_col)[valor_col].sum()

# Tabla de resumen
modalidad_df = pd.DataFrame({
    "Cantidad de contratos": modalidad_dist,
    "Valor total contratado": modalidad_valores
})
print("\nIndicador 4 - Distribuci√≥n por modalidad de contrataci√≥n:")
display(modalidad_df)

# Gr√°fico
plt.figure(figsize=(10, 6))
sns.barplot(x=modalidad_dist.values, y=modalidad_dist.index, palette="Greens_d")
plt.title("Indicador 4 - Distribuci√≥n por modalidad de contrataci√≥n")
plt.xlabel("Cantidad de contratos")
plt.ylabel("Modalidad de contrataci√≥n")
plt.tight_layout()
plt.show()

# Almacenar resultados
for modalidad, cantidad in modalidad_dist.items():
    valor = modalidad_valores.get(modalidad, 0)
    indicadores_resultados.append({
        "Indicador": f"Distribuci√≥n por modalidad de contrataci√≥n - {modalidad}",
        "Resultado": f"{cantidad} contratos, ${valor:,.0f}"
    })

# === Indicador 5: Cumplimiento de plazos contractuales (pr√≥rrogas) ===
dias_adicionados_col = "dias_adicionados (Contratos_electronicos)"
df[dias_adicionados_col] = pd.to_numeric(df[dias_adicionados_col], errors='coerce').fillna(0)

contratos_con_prorroga = df[df[dias_adicionados_col] > 0].shape[0]
total_contratos = df.shape[0]
porcentaje_con_prorroga = (contratos_con_prorroga / total_contratos) * 100

print(f"\nIndicador 5 - Contratos con pr√≥rroga: {contratos_con_prorroga} de {total_contratos} "
      f"({porcentaje_con_prorroga:.2f}%)")

indicadores_resultados.append({
    "Indicador": "Cumplimiento de plazos contractuales (con pr√≥rroga)",
    "Resultado": f"{porcentaje_con_prorroga:.2f}% ({contratos_con_prorroga} contratos)"
})

# Gr√°fico de torta
plt.figure(figsize=(6, 6))
plt.pie([contratos_con_prorroga, total_contratos - contratos_con_prorroga],
        labels=["Con pr√≥rroga", "Sin pr√≥rroga"], autopct='%1.1f%%', startangle=90,
        colors=["#FF9999", "#99FF99"])
plt.title("Indicador 5 - Proporci√≥n de contratos con pr√≥rroga")
plt.tight_layout()
plt.show()

# === Indicador 6: Duraci√≥n promedio de los contratos ===

## dividir entre persoan juruduca y natural

fecha_inicio = "fecha_de_firma (Contratos_electronicos)"
fecha_fin = "fecha_de_fin_del_contrato (Contratos_electronicos)"

df[fecha_inicio] = pd.to_datetime(df[fecha_inicio], errors='coerce')
df[fecha_fin] = pd.to_datetime(df[fecha_fin], errors='coerce')

df["duracion_dias"] = (df[fecha_fin] - df[fecha_inicio]).dt.days
duracion_promedio = df["duracion_dias"].mean()

print(f"\nIndicador 6 - Duraci√≥n promedio de los contratos: {duracion_promedio:.2f} d√≠as")

indicadores_resultados.append({
    "Indicador": "Duraci√≥n promedio de los contratos",
    "Resultado": f"{duracion_promedio:.2f} d√≠as"
})


# === Visualizaci√≥n ===
plt.figure(figsize=(8, 5))
sns.histplot(df["duracion_dias"].dropna(), bins=30, kde=True)
plt.title("Indicador 6 - Duraci√≥n promedio de contratos (d√≠as)")
plt.xlabel("Duraci√≥n (d√≠as)")
plt.ylabel("N√∫mero de contratos")
plt.tight_layout()
plt.show()

# === Indicador 7: Contratos liquidados formalmente ===
col_liquidado = "liquidaci_n (Contratos_electronicos)"
if col_liquidado in df.columns:
    df[col_liquidado] = df[col_liquidado].astype(str).str.upper()
    liquidados = df[df[col_liquidado] == "SI"]
    total_contratos = df.shape[0]
    porcentaje_liquidados = (len(liquidados) / total_contratos) * 100

    print(f"Indicador 7 - Contratos liquidados: {len(liquidados)} de {total_contratos} ({porcentaje_liquidados:.2f}%)")
    indicadores_resultados.append({
        "Indicador": "Porcentaje de contratos liquidados formalmente",
        "Resultado": f"{porcentaje_liquidados:.2f}% ({len(liquidados)} contratos)"
    })

# === Indicador 8: Ejecuci√≥n financiera promedio ===
valor_contrato = "valor_del_contrato (Contratos_electronicos)"
valor_pagado = "valor_pagado (Contratos_electronicos)"
df[valor_contrato] = pd.to_numeric(df[valor_contrato], errors='coerce').fillna(0)
df[valor_pagado] = pd.to_numeric(df[valor_pagado], errors='coerce').fillna(0)

df["ejecucion_%"] = (df[valor_pagado] / df[valor_contrato]) * 100
ejecucion_promedio = df["ejecucion_%"].mean()

print(f"Indicador 8 - Ejecuci√≥n financiera promedio: {ejecucion_promedio:.2f}%")
indicadores_resultados.append({
    "Indicador": "Ejecuci√≥n financiera promedio (valor pagado vs contratado)",
    "Resultado": f"{ejecucion_promedio:.2f}%"
})

# Visualizaci√≥n
plt.figure(figsize=(6, 5))
sns.boxplot(x=df["ejecucion_%"])
plt.title("Indicador 8 - Distribuci√≥n de ejecuci√≥n financiera (%)")
plt.xlabel("Ejecuci√≥n (%)")
plt.tight_layout()
plt.show()

# === Indicador 9: Contratos con pago anticipado ===
anticipo_col = "habilita_pago_adelantado (Contratos_electronicos)"
valor_anticipo_col = "valor_de_pago_adelantado (Contratos_electronicos)"
df[anticipo_col] = df[anticipo_col].astype(str).str.upper()
df[valor_anticipo_col] = pd.to_numeric(df[valor_anticipo_col], errors='coerce').fillna(0)

contratos_anticipo = df[df[anticipo_col] == "SI"]
porcentaje_anticipo = (len(contratos_anticipo) / len(df)) * 100
valor_anticipado = contratos_anticipo[valor_anticipo_col].sum()

print(f"Indicador 9 - Contratos con anticipo: {len(contratos_anticipo)} ({porcentaje_anticipo:.2f}%)")
print(f"Valor total anticipado: ${valor_anticipado:,.0f}")

indicadores_resultados.append({
    "Indicador": "Contratos con pago anticipado",
    "Resultado": f"{porcentaje_anticipo:.2f}% ({len(contratos_anticipo)} contratos), Total anticipado: ${valor_anticipado:,.0f}"
})

# === Indicador 10: Concentraci√≥n de proveedores (Top 5) ===
valor_contrato = "valor_del_contrato (Contratos_electronicos)"
proveedor_col = "proveedor_adjudicado (Contratos_electronicos)"
df[valor_contrato] = pd.to_numeric(df[valor_contrato], errors='coerce').fillna(0)

concentracion = df.groupby(proveedor_col)[valor_contrato].sum().sort_values(ascending=False)
top5_valor = concentracion.head(5).sum()
total_valor = df[valor_contrato].sum()
porcentaje_top5 = (top5_valor / total_valor) * 100

print(f"\nIndicador 10 - Top 5 proveedores concentran el {porcentaje_top5:.2f}% del valor contratado")

indicadores_resultados.append({
    "Indicador": "Concentraci√≥n de proveedores (Top 5)",
    "Resultado": f"{porcentaje_top5:.2f}% del total contratado (${top5_valor:,.0f})"
})

# Visualizaci√≥n
plt.figure(figsize=(10, 5))
sns.barplot(x=concentracion.head(5).values, y=concentracion.head(5).index, palette="Oranges_d")
plt.title("Indicador 10 - Principales 5 proveedores por valor contratado")
plt.xlabel("Valor contratado")
plt.ylabel("Proveedor")
plt.tight_layout()
plt.show()

# === Indicador 11: Diversidad de oferentes ===
proveedores_unicos = df[proveedor_col].nunique()
indice_diversidad = proveedores_unicos / len(df) * 100

print(f"\nIndicador 11 - {proveedores_unicos} proveedores √∫nicos ({indice_diversidad:.2f}% de los contratos)")

indicadores_resultados.append({
    "Indicador": "Diversidad de oferentes",
    "Resultado": f"{proveedores_unicos} proveedores √∫nicos ({indice_diversidad:.2f}% del total de contratos)"
})

# === Indicador 12: Contratos suspendidos ===
estado_col = "estado_contrato (Contratos_electronicos)"
df[estado_col] = df[estado_col].astype(str).str.upper()
suspendidos = df[df[estado_col].str.contains("SUSPENDIDO", na=False)]
porcentaje_suspendidos = (len(suspendidos) / len(df)) * 100

print(f"\nIndicador 12 - Contratos suspendidos: {len(suspendidos)} ({porcentaje_suspendidos:.2f}%)")

indicadores_resultados.append({
    "Indicador": "Contratos suspendidos",
    "Resultado": f"{porcentaje_suspendidos:.2f}% ({len(suspendidos)} contratos)"
})

# Crear DataFrame desde la lista de resultados
resultados_df = pd.DataFrame(indicadores_resultados)

# Guardar a archivo Excel
nombre_archivo = "Bateria_Indicadores_SECOP.xlsx"
resultados_df.to_excel(nombre_archivo, sheet_name="Indicadores", index=False)


#############------------------------------------####################

"""**II. COMPARACI√ìN BASES DE DATOS DE SECOP Y LA BASE DE DATOS DE GESTI√ìN ADMINISTRATIVA**

**0.CARGAR LA BASE DE DATOS DE GESTI√ìN ADMINISTRATIVA**
"""

import os

# Renombrar archivo
os.rename("SECOP_ATENEA_TOTAL.xlsx", "SECOP_DATOSABIERTOS.xlsx")

# --- Si lo necesitas por primera vez ---
!pip -q install pandas openpyxl rapidfuzz unidecode

import pandas as pd
import numpy as np
from rapidfuzz import process, fuzz
from unidecode import unidecode
from google.colab import files

# ==============================
# 0) Par√°metros
# ==============================
THRESHOLD = 20  # ‚Üê si el __matchScore__ global es menor, no se anexa nada de SECOP

# ==============================
# 1) Leer DataFrames ya presentes en el entorno
# ==============================
df_ga    = pd.read_excel('GestionAdministrativa.xlsx')     # left table
df_secop = pd.read_excel('SECOP_DATOSABIERTOS.xlsx')       # right table

print("‚úÖ Cargados:")
print(" - GestionAdministrativa:", df_ga.shape)
print(" - SECOP_DATOSABIERTOS:", df_secop.shape)

# ==============================
# 2) Columnas a comparar (tu lista)
# ==============================
cols_cmp = [
    "referencia_del_contrato (Contratos_electronicos)",
    "modalidad_de_contratacion (Contratos_electronicos)",
    "tipo_de_contrato (Contratos_electronicos)",
    "proveedor_adjudicado (Contratos_electronicos)",
    "tipodocproveedor (Contratos_electronicos)",
    "nacionalidad_representante_legal (Contratos_electronicos)",
    "documento_proveedor (Contratos_electronicos)",
    "nombre_del_banco (Contratos_electronicos)",
    "descripcion_del_proceso (Contratos_electronicos)",
    "valor_del_contrato (Contratos_electronicos)",
    "nombre_supervisor (Contratos_electronicos)",
    "n_mero_de_documento_supervisor (Contratos_electronicos)",
    "urlproceso (Contratos_electronicos)",
    "fecha_de_firma (Contratos_electronicos)",
    "fecha_de_inicio_del_contrato (Contratos_electronicos)",
    "fecha_de_fin_del_contrato (Contratos_electronicos)",
    "duraci_n_del_contrato (Contratos_electronicos)"
]

def faltantes(df, nombre):
    missing = [c for c in cols_cmp if c not in df.columns]
    if missing:
        print(f"‚ö† {nombre} sin columnas: {missing}")
    return [c for c in cols_cmp if c in df.columns]

cols_ga    = faltantes(df_ga,    "GestionAdministrativa")
cols_secop = faltantes(df_secop, "SECOP_DATOSABIERTOS")
cols_common = [c for c in cols_cmp if c in cols_ga and c in cols_secop]
if not cols_common:
    raise ValueError("No hay columnas en com√∫n para comparar. Revisa los nombres.")
print("üîó Columnas en com√∫n:", cols_common)

# ==============================
# 3) Normalizaci√≥n para matching
# ==============================
def to_text(x):
    if pd.isna(x):
        return ""
    if isinstance(x, pd.Timestamp):
        return x.strftime("%Y-%m-%d")
    if isinstance(x, (int, float, np.number)):
        # evitar notaci√≥n cient√≠fica
        return str(int(x)) if float(x).is_integer() else f"{float(x):.6f}".rstrip("0").rstrip(".")
    return str(x)

def normalize(s):
    s = to_text(s).strip().lower()
    s = unidecode(s)           # quita tildes
    s = " ".join(s.split())    # colapsa espacios
    return s

ga_norm    = df_ga.copy()
secop_norm = df_secop.copy()

for c in cols_common:
    ga_norm[c+"_norm"]    = ga_norm[c].apply(normalize)
    secop_norm[c+"_norm"] = secop_norm[c].apply(normalize)

def signature_row(row, cols):
    vals = [row.get(c+"_norm", "") for c in cols]
    return " | ".join([v for v in vals if v])

ga_norm["__signature__"]    = ga_norm.apply(lambda r: signature_row(r, cols_common), axis=1)
secop_norm["__signature__"] = secop_norm.apply(lambda r: signature_row(r, cols_common), axis=1)

# ==============================
# 4) Matching: para cada fila de GA, buscar la mejor pareja de SECOP
# ==============================
secop_signatures = secop_norm["__signature__"].tolist()

best_idx   = []
best_score = []

for sig in ga_norm["__signature__"]:
    if not sig:
        best_idx.append(None)
        best_score.append(np.nan)
        continue
    match = process.extractOne(sig, secop_signatures, scorer=fuzz.token_set_ratio)
    if match is None:
        best_idx.append(None)
        best_score.append(np.nan)
    else:
        _, score, idx = match
        best_idx.append(idx)
        best_score.append(score)

ga_norm["__secop_idx__"]   = best_idx
ga_norm["__matchScore__"]  = best_score  # score global de la firma (GA vs mejor SECOP)

# ==============================
# 5) Renombrar TODAS las columnas con la fuente
# ==============================
ga_all = df_ga.copy()
ga_all.columns = [f"{c}_GestionAdministrativa" for c in df_ga.columns]

secop_all = df_secop.copy()
secop_all.columns = [f"{c}_SecopDatosAbiertos" for c in df_secop.columns]

# Placeholder para columnas SECOP alineadas a GA (left join)
secop_place = pd.DataFrame(np.nan, index=ga_all.index, columns=secop_all.columns)

# Rellenar SOLO si el score global supera el umbral
for i, (idx, s) in enumerate(zip(ga_norm["__secop_idx__"], ga_norm["__matchScore__"])):
    if idx is not None and not pd.isna(s) and s >= THRESHOLD:
        secop_place.iloc[i, :] = secop_all.iloc[int(idx), :]

# ==============================
# 6) Construir resultado (Left Merge: GA + [SECOP si score >= THRESHOLD])
# ==============================
result = pd.concat([ga_all, secop_place], axis=1)
result["__matchScore__"] = ga_norm["__matchScore__"].values

# ==============================
# 7) matchingScore por columna (solo si la fila super√≥ el umbral)
# ==============================
def col_similarity(a, b):
    a_norm = normalize(a)
    b_norm = normalize(b)
    if not a_norm and not b_norm:
        return np.nan
    return fuzz.token_set_ratio(a_norm, b_norm)

for c in cols_common:
    score_col = f"{c}_matchingScore"
    scores = []
    for i, (idx, s) in enumerate(zip(ga_norm["__secop_idx__"], ga_norm["__matchScore__"])):
        if idx is None or pd.isna(s) or s < THRESHOLD:
            scores.append(np.nan)
        else:
            scores.append(col_similarity(df_ga.iloc[i][c], df_secop.iloc[int(idx)][c]))
    result[score_col] = scores

# Asegurar que las columnas comparadas aparezcan con ambos sufijos en el resultado
for c in cols_common:
    secop_col = f"{c}_SecopDatosAbiertos"
    ga_col    = f"{c}_GestionAdministrativa"
    if ga_col not in result.columns and c in df_ga.columns:
        result[ga_col] = df_ga[c]
    if secop_col not in result.columns and c in df_secop.columns:
        # si nunca hubo match por debajo del umbral, igual la columna existir√° (todo NaN)
        result[secop_col] = np.nan

# ==============================
# 8) Guardar archivo completo
# ==============================
OUT1 = "SECOP_ADMINISTATIVA_COMPARACI√ìN.xlsx"
with pd.ExcelWriter(OUT1, engine="openpyxl") as w:
    result.to_excel(w, index=False, sheet_name="LeftMerge_GA_to_SECOP")
print("üíæ Archivo generado:", OUT1)

files.download(OUT1)

# ==============================
# 9) Archivo con SOLO las columnas comparadas (tr√≠os) + __matchScore__
#     Orden por columna: <Secop>, <GA>, <*_matchingScore>
#     (y __matchScore__ al inicio)
# ==============================
ordered_cols = []
if "__matchScore__" in result.columns:
    ordered_cols.append("__matchScore__")

for c in cols_common:
    ordered_cols += [
        f"{c}_SecopDatosAbiertos",
        f"{c}_GestionAdministrativa",
        f"{c}_matchingScore"
    ]

# Filtrar solo las existentes (por si alguna columna faltaba)
ordered_cols = [c for c in ordered_cols if c in result.columns]

comparacion_cols_df = result[ordered_cols].copy()
OUT2 = "ComparacionColumas.xlsx"
with pd.ExcelWriter(OUT2, engine="openpyxl") as w:
    comparacion_cols_df.to_excel(w, index=False, sheet_name="ComparacionCols")
print("üíæ Archivo generado:", OUT2)

###files.download(OUT2)

"""**Exportar base de datos**"""


outfile = "SECOP_ATENEA_TOTAL.xlsx"
SECOP_ATENEA_TOTAL.to_excel(outfile, index=False, engine="openpyxl")


# Cargar las dos bases
df1 = pd.read_excel("SECOP_ATENEA_TOTAL.xlsx")
df2 = pd.read_excel("ComparacionColumas.xlsx")

# Crear un √∫nico archivo Excel con dos pesta√±as
with pd.ExcelWriter("SECOP_Atenea_DatosAbiertos.xlsx", engine="openpyxl") as writer:
    df1.to_excel(writer, sheet_name="SECOP_DatosAbiertos", index=False)
    df2.to_excel(writer, sheet_name="ComparacionSECOP_GestionAdministrativa", index=False)

# Descargar autom√°ticamente el archivo en Colab
files.download("SECOP_Atenea_DatosAbiertos.xlsx")

"""**AN√ÅLISIS DE CALIDAD DE LA INFORMACI√ìN**"""

